# Here is List of Important Literatures Reviews! 

## Part 1 LiteratureS Review

### 1. Supervised Learning Data Augmentation 


+ **RandAugment --> paper Link: https://arxiv.org/abs/1909.13719** . 

*Code Implementation* (Imgaug API -21, TFA API-14 transformation)

+ **AutoAugment --> paper Link https://arxiv.org/abs/1805.09501** 

*Code Implementation* (TFA -API for V0 policy implementation)

+ **FastAuto Augment --> paper Link https://arxiv.org/abs/1905.00397** 

**Code Implementation* (Original Github Repository)
https://github.com/kakaobrain/fast-autoaugment

+ **An uncertainty-based random sampling algorithm for data augmentation --> Paper Link https://arxiv.org/abs/2005.00695 ** 

**Code Implementation* (Original Github Repository)
https://github.com/senwu/dauphin


### 2. Supervised Regularization Techniques 

+ **Mixup --> Paper Link https://arxiv.org/abs/1710.09412**
**Code Implementation --> Check out our repository**


+ **Cutmix --> Paper Link https://arxiv.org/abs/1905.04899?context=cs.CV**
**Code Implementation --> Check out our repository**


+ **Manifold Mixup --> Paper Link https://arxiv.org/abs/1806.05236**

**Code Implementation --> Check out our repository**



## Part 2 LiteratureS Review

### 1. Self-Supervised DataAugmentation

+ **SimCLR Augmentation Strategy paper link https://arxiv.org/abs/2002.05709**

+ **SelfAugment Bayesian Search augmentation policy paper link https://arxiv.org/abs/2009.07724**

+ **BYOL Augmentation Strategy for Non-Contrastive implementation Paper Link https://arxiv.org/abs/2006.07733**

### 2. Self-Supervised Regularization 

+ **Mix-Co Mixup for Contrastive Learning Paper Link https://arxiv.org/abs/2010.06300**

+ **Mixup + CutMix for Contrastive learning Paper Link https://arxiv.org/abs/2003.05438**

+ ** Towards Domain-Agnostic Contrastive Learning Paper link: http://proceedings.mlr.press/v139/verma21a/verma21a.pdf**
